{"config":{"lang":["it"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Uso di immagini Apptainer/Singularity con HTCondor su ReCaS","text":""},{"location":"#introduzione","title":"Introduzione","text":"<p>Questa guida descrive in modo operativo come usare immagini Apptainer/Singularity (file <code>.sif</code>) insieme a HTCondor sul cluster ReCaS. L\u2019idea di fondo \u00e8 che nel gruppo ci sia almeno un utente \u201cmanutentore\u201d (che chiameremo <code>alice</code>) che possa costruire immagini Docker su una macchina dedicata, convertirle in immagini Apptainer/Singularity e metterle a disposizione di tutti in una posizione condivisa su lustre. Gli altri utenti (ad esempio <code>bob</code>) non devono occuparsi della parte Docker: si limitano a usare le immagini <code>.sif</code> gi\u00e0 pronte all\u2019interno dei job Condor, tramite symlink verso la directory condivisa di <code>alice</code>.</p> <p>Nel seguito useremo come esempio un utente chiamato <code>bob</code> per i job Condor, mentre <code>alice</code> rappresenter\u00e0 l\u2019utente che ospita le immagini condivise. Per rendere gli esempi concreti, si assume che siano gi\u00e0 presenti due immagini Apptainer nella directory condivisa di <code>alice</code>:</p> Bash<pre><code>/lustrehome/alice/apptainer_images/G4_v10.6.3_NOMULTITHREAD.sif\n/lustrehome/alice/apptainer_images/G4_v11.3.1.sif\n</code></pre> <p>Queste immagini contengono Ubuntu 24.04, Geant4, ROOT, Python3 con numpy e matplotlib. In particolare l\u2019immagine <code>G4_v10.6.3_NOMULTITHREAD.sif</code> ha il multithreading disattivato per Geant4 ed \u00e8 adatta ad applicazioni che richiedono esecuzione single-thread.</p> <p>La sezione Concetti di base: container, Apptainer e HTCondor introduce i concetti di base su container, Apptainer e HTCondor, mentre la sezione Organizzazione delle directory propone una convenzione semplice per organizzare le directory su lustre dal punto di vista di <code>bob</code>. La sezione Esempi illustra cinque esempi completi di utilizzo: test dell\u2019immagine, build dell\u2019esempio B5 di Geant4, run di B5, build+run in un unico job e un caso reale con una simulazione Geant di una tile scintillante tra due piani di fibre WLS (CsI-WLS) e Python. La sezione Costruzione di un\u2019immagine Docker e conversione in SIF mostra come costruire e convertire immagini Docker in <code>.sif</code>, mentre la sezione Prospettive: uso di Kubernetes con container \u00e8 prevista come estensione futura. In Appendice, la sezione Dockerfile di esempio per ambiente Geant4/ROOT contiene un Dockerfile di esempio.</p>"},{"location":"#sec-concetti-base","title":"Concetti di base: container, Apptainer e HTCondor","text":"<p>Prima di entrare negli esempi conviene chiarire cosa si intende per container e come Apptainer interagisce con HTCondor nel contesto del cluster ReCaS.</p> <p>Un container \u00e8 un ambiente software isolato, definito da un\u2019immagine che contiene un sistema operativo minimale (ad esempio Ubuntu), le librerie e le applicazioni necessarie. Quando si avvia un container, il programma viene eseguito con quell\u2019ambiente software, indipendentemente dal sistema operativo del nodo fisico. Nel nostro caso un\u2019immagine <code>.sif</code> contiene Geant4, ROOT, Python e le relative dipendenze, cos\u00ec che un job Condor non deve installare o configurare nulla: trova tutto gi\u00e0 predisposto.</p> <p>Su ReCaS i container sono gestiti da Apptainer (discendente di Singularity), progettato per ambienti HPC multiutente. Un\u2019immagine Apptainer \u00e8 un file in sola lettura; durante il job, Apptainer monta il filesystem dell\u2019immagine e allo stesso tempo monta la directory di lavoro dell\u2019utente, in modo che il programma possa leggere e scrivere i propri file su lustre. Questo approccio \u00e8 pi\u00f9 leggero di una macchina virtuale, perch\u00e9 il kernel del sistema \u00e8 condiviso e si avvia solo lo strato utente.</p> <p>HTCondor si occupa di individuare i worker node disponibili, preparare la directory di lavoro e avviare Apptainer. Dal punto di vista dell\u2019utente, la cosa fondamentale \u00e8 capire il ruolo di tre parametri nel file di submit: <code>initialdir</code>, <code>executable</code> e <code>container_image</code>.</p> <ul> <li>La direttiva <code>initialdir</code> indica la directory sul filesystem di lustre che rappresenta la cartella di lavoro del job. Condor monta questa directory nel container come current working directory (CWD), quindi tutto ci\u00f2 che viene scritto in CWD o in sottocartelle relative finisce direttamente in questa directory su lustre.</li> <li>La direttiva <code>executable</code> indica lo script o l\u2019eseguibile che verr\u00e0 lanciato all\u2019interno del container. Deve trovarsi nella <code>initialdir</code> o in una sua sottocartella ed \u00e8 specificato nel file di submit con un percorso relativo.</li> <li>La direttiva <code>container_image</code> indica quale immagine Apptainer usare. I test effettuati sul cluster hanno mostrato un comportamento pratico importante: Condor si aspetta che il valore di <code>container_image</code> sia il nome di un file presente nella <code>initialdir</code>. Per questa ragione, anche se l\u2019immagine \u201creale\u201d vive in una directory centrale, per ogni job conviene creare nella <code>initialdir</code> un symlink locale all\u2019immagine e poi usare nel submit il nome del symlink (ad esempio un symlink a <code>/lustrehome/alice/apptainer_images/immagine.sif</code>).</li> </ul> <p>Un esempio tipico \u00e8 il seguente. Nella directory del job di <code>bob</code> si crea un link all\u2019immagine condivisa di <code>alice</code>:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v11.3.1.sif \\\n       G4_v11.3.1.sif\n</code></pre> <p>e nel file di submit si scrive:</p> Bash<pre><code>container_image = G4_v11.3.1.sif\n</code></pre> <p>In questo modo Condor trova il file <code>G4_v11.3.1.sif</code> nella <code>initialdir</code>, avvia Apptainer con quell\u2019immagine e monta la <code>initialdir</code> all\u2019interno del container. Da quel momento in poi lo script <code>executable</code> viene eseguito dentro il container e la directory di lavoro corrisponde alla directory dell\u2019utente su lustre.</p> <p>Gli esempi pratici della sezione Esempi non fanno altro che declinare questo schema base in casi d\u2019uso via via pi\u00f9 complessi.</p>"},{"location":"#sec-organizzazione","title":"Organizzazione delle directory","text":"<p>Per lavorare in modo ordinato conviene scegliere una convenzione semplice all\u2019interno della propria home su lustre. Nel caso di <code>bob</code>, la directory di riferimento per i job \u00e8 <code>/lustrehome/bob</code>, mentre l\u2019utente manutentore <code>alice</code> usa <code>/lustrehome/alice</code> per ospitare le immagini condivise.</p> <p>Le immagini Apptainer condivise dal manutentore possono essere raccolte in una directory dedicata, ad esempio <code>/lustrehome/alice/apptainer_images</code>. In questa directory si collocano i file <code>.sif</code> che <code>alice</code> ha costruito o recuperato. Nel nostro esempio vi si trovano <code>G4_v11.3.1.sif</code> e <code>G4_v10.6.3_NOMULTITHREAD.sif</code>.</p> <p>Per gli esempi e i job Condor di <code>bob</code> si pu\u00f2 usare una directory <code>condor_tests</code>. All\u2019interno di <code>condor_tests</code> \u00e8 utile creare sottodirectory dedicate per ciascun tipo di job. Ogni directory contiene i file di submit <code>.csi</code>, gli script <code>.sh</code>, un link locale all\u2019immagine <code>.sif</code> (proveniente da <code>/lustrehome/alice/apptainer_images</code>) e una sottocartella <code>logs/</code> per gli output di Condor. Questa struttura rende chiaro dove si trova il codice sorgente, dove viene compilato il programma e dove finiscono i file prodotti dai job Condor, seguendo lo schema introdotto in Concetti di base: container, Apptainer e HTCondor e utilizzato in tutti gli esempi successivi.</p>"},{"location":"#sec-esempi","title":"Esempi","text":"<p>In questa sezione sono riportati cinque esempi completi che illustrano come utilizzare immagini Apptainer/Singularity in combinazione con HTCondor. Gli esempi seguono un ordine progressivo, dal test pi\u00f9 semplice fino a un caso realistico con un progetto Geant4 personalizzato:</p> <ul> <li>Esempio 1 \u2013 test minimale dell\u2019immagine <code>.sif</code> per verificare la versione di Geant4, ROOT e Python e controllare che il container venga avviato correttamente su un worker node;</li> <li>Esempio 2 \u2013 compilazione dell\u2019esempio Geant4 B5 all\u2019interno del container utilizzando CMake;</li> <li>Esempio 3 \u2013 esecuzione di un binario Geant4 precompilato con una macro, in un job dedicato;</li> <li>Esempio 4 \u2013 compilazione ed esecuzione dell\u2019esempio B5 nello stesso job HTCondor, utile quando si vuole una build \u201cpulita\u201d per ogni run;</li> <li>Esempio 5 \u2013 caso realistico con il progetto CsI-WLS, che prevede build con CMake e un batch di simulazioni pilotato da uno script Python.</li> </ul> <p>I template completi degli script <code>.sh</code> e dei file di submit <code>.csi</code> utilizzati negli esempi successivi sono disponibili al seguente link:</p> <p>https://politecnicobari-my.sharepoint.com/:f:/g/personal/m_cecca1_phd_poliba_it/IgB8X8DaFI3QTaVAEtIk1-7vAavKvy_XEBCvTr6rky2CQf8?e=si0j3J</p>"},{"location":"#sec-esempio1","title":"Esempio 1: test dell'immagine Geant4","text":"<p>Il primo esempio ha lo scopo di verificare che l\u2019immagine <code>G4_v11.3.1.sif</code> funzioni correttamente su un worker node. L\u2019obiettivo \u00e8 sapere su quale nodo gira il job, quali versioni di Geant4, ROOT e Python sono visibili dall\u2019interno del container e se l\u2019ambiente \u00e8 coerente.</p> <p>Si inizia creando la directory del test e una sottocartella per i log:</p> Bash<pre><code>cd /lustrehome/bob\nmkdir -p condor_tests/test_container/logs\ncd condor_tests/test_container\n</code></pre> <p>Si crea un link all\u2019immagine condivisa di <code>alice</code>:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v11.3.1.sif \\\n       G4_v11.3.1.sif\n</code></pre> <p>Lo script <code>test_container.sh</code>, che sar\u00e0 eseguito dentro il container, pu\u00f2 essere definito come segue:</p> Bash<pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"[TEST] Start: $(date)\"\necho \"[TEST] Host:  $(hostname)\"\necho \"[TEST] User:  $(whoami)\"\necho \"[TEST] Pwd:   $(pwd)\"\necho\n\necho \"[TEST] Environment snippet:\"\necho \"  G4INSTALL=${G4INSTALL:-undefined}\"\necho \"  G4VERSION=${G4VERSION:-undefined}\"\necho \"  ROOTSYS=${ROOTSYS:-undefined}\"\necho\n\necho \"[TEST] Checking Geant4 / ROOT / Python...\"\ncommand -v geant4-config  &gt;/dev/null 2&gt;&amp;1 &amp;&amp; \\\n  geant4-config --version || echo \"geant4-config NOT found\"\ncommand -v root-config    &gt;/dev/null 2&gt;&amp;1 &amp;&amp; \\\n  root-config --version   || echo \"root-config NOT found\"\ncommand -v python3        &gt;/dev/null 2&gt;&amp;1 &amp;&amp; \\\n  python3 --version       || echo \"python3 NOT found\"\necho\n\npython3 - &lt;&lt; 'EOF'\nimport sys, platform\nprint(\"Python:\", sys.version.split()[0])\nprint(\"Platform:\", platform.platform())\nEOF\n\necho\necho \"[TEST] Done: $(date)\"\n</code></pre> <p>Lo script va reso eseguibile:</p> Bash<pre><code>chmod +x test_container.sh\n</code></pre> <p>Il file di submit <code>test_container.csi</code> specifica la directory iniziale, lo script da eseguire e l\u2019immagine da usare:</p> Bash<pre><code>universe        = vanilla\n\ninitialdir      = /lustrehome/bob/condor_tests/test_container\n\nexecutable      = test_container.sh\narguments       =\n\ncontainer_image = G4_v11.3.1.sif\n\nrequest_cpus    = 1\nrequest_memory  = 1 GB\nrequest_disk    = 4 GB\n\noutput          = logs/test_$(ClusterId).$(ProcId).out\nerror           = logs/test_$(ClusterId).$(ProcId).err\nlog             = logs/test_$(ClusterId).$(ProcId).log\n\nqueue 1\n</code></pre> <p>La sottomissione avviene con:</p> Bash<pre><code>condor_submit test_container.csi\n</code></pre> <p>Quando il job \u00e8 completato, il file <code>logs/test_...out</code> contiene le informazioni stampate dallo script: il nome del worker node, l\u2019utente, la directory di lavoro, le variabili di ambiente e le versioni dei software principali. Questo conferma che l\u2019immagine \u00e8 correttamente utilizzabile con HTCondor secondo lo schema introdotto in Concetti di base: container, Apptainer e HTCondor.</p>"},{"location":"#sec-esempio2","title":"Esempio 2: build dell\u2019esempio B5 di Geant4","text":"<p>Il secondo esempio mostra come compilare l\u2019esempio B5 di Geant4 usando l\u2019immagine <code>G4_v11.3.1.sif</code>. L\u2019obiettivo \u00e8 ottenere l\u2019eseguibile <code>exampleB5</code> in una directory di build gestita dal job.</p> <p>Si crea la directory del test di build:</p> Bash<pre><code>cd /lustrehome/bob\nmkdir -p condor_tests/build_B5_11.3.1/logs\ncd condor_tests/build_B5_11.3.1\n</code></pre> <p>Si collega l\u2019immagine condivisa:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v11.3.1.sif \\\n       G4_v11.3.1.sif\n</code></pre> <p>Lo script <code>build_B5_exec.sh</code> viene eseguito dentro il container e si occupa di configurare e compilare il progetto:</p> Bash<pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"[BUILD] Start: $(date)\"\necho \"[BUILD] Host:  $(hostname)\"\necho \"[BUILD] User:  $(whoami)\"\necho \"[BUILD] Pwd:   $(pwd)\"\necho\n\nSRC_DIR=\"/opt/geant4/share/Geant4/examples/basic/B5\"\nBUILD_DIR=\"B5_build_condor\"\n\necho \"[BUILD] SRC_DIR   = ${SRC_DIR}\"\necho \"[BUILD] BUILD_DIR = ${BUILD_DIR}\"\necho\n\nif [[ -f /opt/geant4/bin/geant4.sh ]]; then\n  echo \"[BUILD] Sourcing Geant4...\"\n  source /opt/geant4/bin/geant4.sh\nfi\n\nif [[ -f /opt/root/bin/thisroot.sh ]]; then\n  echo \"[BUILD] Sourcing ROOT...\"\n  source /opt/root/bin/thisroot.sh\nfi\n\nmkdir -p \"${BUILD_DIR}\"\ncd \"${BUILD_DIR}\"\n\necho \"[BUILD] Now in: $(pwd)\"\n\necho \"[BUILD] Running CMake...\"\ncmake \"${SRC_DIR}\"\n\necho \"[BUILD] Building...\"\ncmake --build . -- -j\"$(nproc)\"\n\necho\necho \"[BUILD] Done: $(date)\"\n</code></pre> <p>Lo script viene reso eseguibile:</p> Bash<pre><code>chmod +x build_B5_exec.sh\n</code></pre> <p>Il file di submit <code>build_B5_11.3.1.csi</code> \u00e8:</p> Bash<pre><code>universe        = vanilla\n\ninitialdir      = /lustrehome/bob/condor_tests/build_B5_11.3.1\n\nexecutable      = build_B5_exec.sh\narguments       =\n\ncontainer_image = G4_v11.3.1.sif\n\nrequest_cpus    = 4\nrequest_memory  = 4 GB\nrequest_disk    = 8 GB\n\noutput          = logs/build_$(ClusterId).$(ProcId).out\nerror           = logs/build_$(ClusterId).$(ProcId).err\nlog             = logs/build_$(ClusterId).$(ProcId).log\n\nqueue 1\n</code></pre> <p>Il job si sottomette con:</p> Bash<pre><code>condor_submit build_B5_11.3.1.csi\n</code></pre> <p>Al termine della compilazione, nella directory <code>/lustrehome/bob/condor_tests/build_B5_11.3.1/B5_build_condor</code> si trovano i file di CMake e l\u2019eseguibile <code>exampleB5</code>. Lo standard output del job contiene i messaggi di CMake e l\u2019esito del build, che verr\u00e0 riutilizzato nella sezione Esempio 3: run dell\u2019esempio B5.</p>"},{"location":"#sec-esempio3","title":"Esempio 3: run dell\u2019esempio B5","text":"<p>Il terzo esempio riutilizza l\u2019eseguibile <code>exampleB5</code> compilato in Esempio 2: build dell\u2019esempio B5 di Geant4 e mostra come preparare una directory di run separata, in cui copiare l\u2019eseguibile e le macro e lanciare la simulazione.</p> <p>Si crea la directory per il run:</p> Bash<pre><code>cd /lustrehome/bob\nmkdir -p condor_tests/run_B5_11.3.1/logs\ncd condor_tests/run_B5_11.3.1\n</code></pre> <p>Si collega l\u2019immagine:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v11.3.1.sif \\\n       G4_v11.3.1.sif\n</code></pre> <p>Si copiano l\u2019eseguibile e la macro <code>run1.mac</code> dalla build:</p> Bash<pre><code>cp /lustrehome/bob/condor_tests/build_B5_11.3.1/B5_build_condor/exampleB5 .\ncp /lustrehome/bob/condor_tests/build_B5_11.3.1/B5_build_condor/run1.mac .\n</code></pre> <p>Lo script <code>run_B5_exec.sh</code> lancia l\u2019eseguibile con la macro:</p> Bash<pre><code>#!/bin/bash\nset -euo pipefail\n\nif [[ $# -lt 2 ]]; then\n  echo \"Usage: $0 &lt;exec_rel_path&gt; &lt;macro_rel_path&gt;\"\n  echo \"Example: $0 exampleB5 run1.mac\"\n  exit 1\nfi\n\nEXEC_REL=\"$1\"\nMACRO_REL=\"$2\"\n\necho \"[RUN] Start: $(date)\"\necho \"[RUN] Host:  $(hostname)\"\necho \"[RUN] User:  $(whoami)\"\necho \"[RUN] Pwd:   $(pwd)\"\necho \"[RUN] Exec:  ${EXEC_REL}\"\necho \"[RUN] Macro: ${MACRO_REL}\"\necho\n\nif [[ -f /opt/geant4/bin/geant4.sh ]]; then\n  echo \"[RUN] Sourcing Geant4...\"\n  source /opt/geant4/bin/geant4.sh\nfi\nif [[ -f /opt/root/bin/thisroot.sh ]]; then\n  echo \"[RUN] Sourcing ROOT...\"\n  source /opt/root/bin/thisroot.sh\nfi\n\nEXEC_PATH=\"./${EXEC_REL}\"\nMACRO_PATH=\"./${MACRO_REL}\"\n\nif [[ ! -x \"${EXEC_PATH}\" ]]; then\n  echo \"[RUN] ERROR: executable not found or not executable: ${EXEC_PATH}\"\n  exit 1\nfi\nif [[ ! -f \"${MACRO_PATH}\" ]]; then\n  echo \"[RUN] ERROR: macro not found: ${MACRO_PATH}\"\n  exit 1\nfi\n\necho \"[RUN] Launching: ${EXEC_PATH} ${MACRO_PATH}\"\n\"${EXEC_PATH}\" \"${MACRO_PATH}\"\n\necho\necho \"[RUN] Done: $(date)\"\n</code></pre> <p>Lo script va reso eseguibile:</p> Bash<pre><code>chmod +x run_B5_exec.sh\n</code></pre> <p>Il file di submit <code>run_B5_11.3.1.csi</code> utilizza lo script, l\u2019immagine e specifica le risorse richieste:</p> Bash<pre><code>universe        = vanilla\n\ninitialdir      = /lustrehome/bob/condor_tests/run_B5_11.3.1\n\nexecutable      = run_B5_exec.sh\narguments       = exampleB5 run1.mac\n\ncontainer_image = G4_v11.3.1.sif\n\nrequest_cpus    = 1\nrequest_memory  = 2 GB\nrequest_disk    = 4 GB\n\noutput          = logs/run_$(ClusterId).$(ProcId).out\nerror           = logs/run_$(ClusterId).$(ProcId).err\nlog             = logs/run_$(ClusterId).$(ProcId).log\n\nqueue 1\n</code></pre> <p>La sottomissione avviene come nei casi precedenti:</p> Bash<pre><code>condor_submit run_B5_11.3.1.csi\n</code></pre> <p>Gli output prodotti da B5 vengono scritti nella directory <code>/lustrehome/bob/condor_tests/run_B5_11.3.1</code>, che corrisponde alla directory di lavoro del job dentro il container, e rimangono quindi disponibili all\u2019utente anche dopo la fine dell\u2019esecuzione.</p>"},{"location":"#sec-esempio4","title":"Esempio 4: build e run di B5 in un unico job","text":"<p>In alcune situazioni \u00e8 comodo compilare il codice e far partire subito il run all\u2019interno dello stesso job Condor. Questo permette di avere un singolo file di submit per l\u2019intera catena e di garantire che il run utilizzi esattamente la build prodotta nel job.</p> <p>Per questo esempio si crea una nuova directory:</p> Bash<pre><code>cd /lustrehome/bob\nmkdir -p condor_tests/build_run_B5_11.3.1/logs\ncd condor_tests/build_run_B5_11.3.1\n</code></pre> <p>Si collega l\u2019immagine Geant4 11.3.1:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v11.3.1.sif \\\n       G4_v11.3.1.sif\n</code></pre> <p>Lo script <code>build_run_B5_exec.sh</code> esegue prima la compilazione dell\u2019esempio B5 e subito dopo l\u2019eseguibile con una macro di esempio:</p> Bash<pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"[BUILD+RUN] Start: $(date)\"\necho \"[BUILD+RUN] Host:  $(hostname)\"\necho \"[BUILD+RUN] User:  $(whoami)\"\necho \"[BUILD+RUN] Pwd:   $(pwd)\"\necho\n\nSRC_DIR=\"/opt/geant4/share/Geant4/examples/basic/B5\"\nBUILD_DIR=\"B5_build_condor\"\nMACRO=\"${SRC_DIR}/run1.mac\"\n\necho \"[BUILD+RUN] SRC_DIR   = ${SRC_DIR}\"\necho \"[BUILD+RUN] BUILD_DIR = ${BUILD_DIR}\"\necho \"[BUILD+RUN] MACRO     = ${MACRO}\"\necho\n\nif [[ -f /opt/geant4/bin/geant4.sh ]]; then\n  echo \"[BUILD+RUN] Sourcing Geant4...\"\n  source /opt/geant4/bin/geant4.sh\nfi\n\nif [[ -f /opt/root/bin/thisroot.sh ]]; then\n  echo \"[BUILD+RUN] Sourcing ROOT...\"\n  source /opt/root/bin/thisroot.sh\nfi\n\nmkdir -p \"${BUILD_DIR}\"\ncd \"${BUILD_DIR}\"\n\necho \"[BUILD+RUN] Now in: $(pwd)\"\n\nif [[ -x exampleB5 ]]; then\n  echo \"[BUILD+RUN] exampleB5 already built, skipping CMake/cmake --build.\"\nelse\n  echo \"[BUILD+RUN] Running CMake...\"\n  cmake \"${SRC_DIR}\"\n\n  echo \"[BUILD+RUN] Building...\"\n  cmake --build . -- -j\"$(nproc)\"\nfi\n\nif [[ ! -x exampleB5 ]]; then\n  echo \"[BUILD+RUN] ERROR: build failed, exampleB5 not found.\"\n  exit 1\nfi\n\necho\necho \"[BUILD+RUN] Running exampleB5 with macro: ${MACRO}\"\n./exampleB5 \"${MACRO}\"\n\necho\necho \"[BUILD+RUN] ROOT files under $(pwd):\"\nfind . -maxdepth 3 -type f -name '*.root' -print || \\\n  echo \"[BUILD+RUN] Nessun .root trovato.\"\n\necho\necho \"[BUILD+RUN] Done: $(date)\"\n</code></pre> <p>Lo script viene reso eseguibile:</p> Bash<pre><code>chmod +x build_run_B5_exec.sh\n</code></pre> <p>Il file di submit <code>build_run_B5_11.3.1.csi</code> \u00e8 il seguente:</p> Bash<pre><code>universe        = vanilla\n\ninitialdir      = /lustrehome/bob/condor_tests/build_run_B5_11.3.1\n\nexecutable      = build_run_B5_exec.sh\narguments       =\n\ncontainer_image = G4_v11.3.1.sif\n\nrequest_cpus    = 4\nrequest_memory  = 4 GB\nrequest_disk    = 8 GB\n\noutput          = logs/build_run_$(ClusterId).$(ProcId).out\nerror           = logs/build_run_$(ClusterId).$(ProcId).err\nlog             = logs/build_run_$(ClusterId).$(ProcId).log\n\nqueue 1\n</code></pre> <p>La sottomissione avviene con:</p> Bash<pre><code>condor_submit build_run_B5_11.3.1.csi\n</code></pre> <p>Alla conclusione del job, la directory <code>B5_build_condor</code> contiene sia i file generati da CMake, sia l\u2019eseguibile <code>exampleB5</code>, sia i file di output del run (ad esempio file ROOT). Tutti questi file risiedono in <code>/lustrehome/bob/condor_tests/build_run_B5_11.3.1/B5_build_condor</code> e sono quindi accessibili per analisi successive.</p>"},{"location":"#sec-esempio5","title":"Esempio 5: progetto CsI-WLS con Python","text":"<p>L\u2019ultimo esempio mostra una situazione pi\u00f9 vicina a un caso reale, in cui un\u2019applicazione Geant4 custom (CsI-WLS) viene compilata da sorgente con CMake e poi eseguita molte volte con parametri diversi, gestiti da uno script Python. Per questo caso si sfrutta l\u2019immagine <code>G4_v10.6.3_NOMULTITHREAD.sif</code>, che contiene Geant4 10.6.3 senza multithreading, ROOT 6.36.4 e Python3 con le librerie principali.</p> <p>Si assume che il progetto CsI-WLS esista gi\u00e0 in una directory di sviluppo, ad esempio <code>/lustrehome/bob/ADAPT/simulation/CsI-WLS_v1.2.2</code>, che contiene una sottodirectory <code>src</code> con i file CMake e il codice. Per rendere il job auto-contenuto dentro <code>condor_tests</code> si copia solo la directory <code>src</code>:</p> Bash<pre><code>cd /lustrehome/bob/condor_tests\nmkdir -p CsI-WLS_v1.2.2\ncp -r /lustrehome/bob/ADAPT/simulation/CsI-WLS_v1.2.2/src CsI-WLS_v1.2.2/\ncd CsI-WLS_v1.2.2\nmkdir -p logs\n</code></pre> <p>Si crea il link all\u2019immagine senza multithreading di <code>alice</code>:</p> Bash<pre><code>ln -sf /lustrehome/alice/apptainer_images/G4_v10.6.3_NOMULTITHREAD.sif \\\n       G4_v10.6.3_NOMULTITHREAD.sif\n</code></pre> <p>Nella directory <code>source</code> (nel testo LaTeX originale si alternano <code>source</code>/<code>src</code>; qui assumiamo che lo script Python sia nella directory con i sorgenti) si definisce lo script Python che si aspetta di essere eseguito da dentro <code>build</code> (dove esiste <code>./CsI-WLS</code>). Questo script genera un certo numero di macro, ognuna con un seed diverso, e per ciascuna macro lancia l\u2019eseguibile:</p> Python<pre><code>import numpy as np\nimport os\nimport matplotlib.pyplot as plt  # non usato, ma non da fastidio\n\nDIR_MAC = \"./mac_electron\"\nDIR_ROOT = \"rootOutput_electron\"\n\nN_EVENTS = 10\nsubdir = \"random_rectangular_source_200keV\"\nnfiles = 50\n\nfor k in range(nfiles):\n    seed1, seed2 = np.random.randint(0, 2**32, size=2)\n\n    mac = (f\"{DIR_MAC}/{subdir}/\"\n           f\"random_rectangular_source_electron_ene_\"\n           f\"200keV_ly1_n{k}.mac\")\n    root = mac.replace(DIR_MAC, DIR_ROOT).replace(\".mac\", \"\")\n\n    os.makedirs(os.path.dirname(mac),  exist_ok=True)\n    os.makedirs(os.path.dirname(root), exist_ok=True)\n\n    with open(mac, \"w\") as f:\n        f.write(\n            \"/run/initialize\\n\"\n            \"/tracking/verbose 0\\n\"\n            \"/gps/particle e-\\n\"\n            \"/gps/position 0 0 0 mm\\n\"\n            \"/gps/direction 0 0 -1\\n\"\n            f\"/random/setSeeds [{seed1} {seed2}]\\n\"\n            \"/gps/pos/type Plane\\n\"\n            \"/gps/pos/shape Rectangle\\n\"\n            \"/gps/pos/halfx 220 mm\\n\"\n            \"/gps/pos/halfy 220 mm\\n\"\n            \"/gps/ene/mono 200 keV\\n\"\n            f\"/RunManager/NameOfOutputFile {root}\\n\"\n            f\"/run/beamOn {N_EVENTS}\\n\"\n        )\n\n    os.system(f\"./CsI-WLS {mac}\")\n\nprint(f\"\\n {N_EVENTS*nfiles} eventi salvati in \"\n      f\"{DIR_MAC}/{subdir} e simulati con ./CsI-WLS\")\n</code></pre> <p>Questo file pu\u00f2 essere salvato come <code>src/run_electrons_batch.py</code> (o <code>source/run_electrons_batch.py</code>, a seconda della struttura del progetto) all\u2019interno della copia di CsI-WLS sotto <code>condor_tests</code>.</p> <p>Nella root della directory <code>CsI-WLS_v1.2.2</code> si definisce lo script <code>run_CsI_WLS_electron_batch.sh</code>, che compila il progetto nella directory <code>build</code> e poi lancia lo script Python:</p> Bash<pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"[PYRUN] Start: $(date)\"\necho \"[PYRUN] Host: $(hostname)\"\necho \"[PYRUN] User: $(whoami)\"\necho \"[PYRUN] Pwd:  $(pwd)\"\necho\n\nif [[ -f /opt/geant4/bin/geant4.sh ]]; then\n  echo \"[PYRUN] Sourcing Geant4...\"\n  source /opt/geant4/bin/geant4.sh\nfi\nif [[ -f /opt/root/bin/thisroot.sh ]]; then\n  echo \"[PYRUN] Sourcing ROOT...\"\n  source /opt/root/bin/thisroot.sh\nfi\n\nBUILD_DIR=\"build\"\nSRC_DIR=\"source\"\n\nmkdir -p \"${BUILD_DIR}\"\ncd \"${BUILD_DIR}\"\n\necho \"[PYRUN] Now in build dir: $(pwd)\"\n\nif [[ -x CsI-WLS ]]; then\n  echo \"[PYRUN] CsI-WLS already built, skipping cmake/cmake --build.\"\nelse\n  echo \"[PYRUN] Configuring with CMake...\"\n  cmake \"../${SRC_DIR}\"\n\n  echo \"[PYRUN] Building CsI-WLS...\"\n  cmake --build . -- -j\"$(nproc)\"\nfi\n\nif [[ ! -x CsI-WLS ]]; then\n  echo \"[PYRUN] ERROR: CsI-WLS binary not found after build.\"\n  exit 1\nfi\n\necho\necho \"[PYRUN] Running Python batch script...\"\npython3 ../source/run_electrons_batch.py\n\necho\necho \"[PYRUN] ROOT files under rootOutput_electron/:\"\nfind rootOutput_electron -maxdepth 3 -type f -name '*.root' -print \\\n  || echo \"[PYRUN] Nessun .root trovato.\"\n\necho\necho \"[PYRUN] Done at $(date)\"\n</code></pre> <p>Lo script va reso eseguibile:</p> Bash<pre><code>chmod +x run_CsI_WLS_electron_batch.sh\n</code></pre> <p>Infine si definisce il file di submit <code>CsI_WLS_python_electrons.csi</code>:</p> Bash<pre><code>universe        = vanilla\n\ninitialdir      = /lustrehome/bob/condor_tests/CsI-WLS_v1.2.2\n\nexecutable      = run_CsI_WLS_electron_batch.sh\narguments       =\n\ncontainer_image = G4_v10.6.3_NOMULTITHREAD.sif\n\nrequest_cpus    = 1\nrequest_memory  = 2 GB\nrequest_disk    = 16 GB\n\noutput          = logs/pyCsI_$(ClusterId).$(ProcId).out\nerror           = logs/pyCsI_$(ClusterId).$(ProcId).err\nlog             = logs/pyCsI_$(ClusterId).$(ProcId).log\n\nqueue 1\n</code></pre> <p>La sottomissione avviene con:</p> Bash<pre><code>cd /lustrehome/bob/condor_tests/CsI-WLS_v1.2.2\ncondor_submit CsI_WLS_python_electrons.csi\n</code></pre> <p>Quando il job \u00e8 terminato, nella directory <code>build</code> compaiono l\u2019eseguibile <code>CsI-WLS</code>, le macro generate dallo script Python e gli output ROOT. Tutti questi file sono salvati su lustre dentro <code>/lustrehome/bob/condor_tests/CsI-WLS_v1.2.2</code>.</p> <p>I template completi degli script <code>.sh</code> e dei file di submit <code>.csi</code> utilizzati negli esempi nella sezione Esempi sono presenti al seguente link:</p> <p>https://politecnicobari-my.sharepoint.com/:f:/g/personal/m_cecca1_phd_poliba_it/IgB8X8DaFI3QTaVAEtIk1-7vAavKvy_XEBCvTr6rky2CQf8?e=si0j3J</p>"},{"location":"#sec-docker-sif","title":"Costruzione di un\u2019immagine Docker e conversione in SIF","text":"<p>Gli esempi della sezione Esempi assumono che le immagini <code>.sif</code> siano gi\u00e0 disponibili in una cartella condivisa, gestita dall\u2019utente <code>alice</code>. Questa sezione descrive in modo sintetico come costruire un\u2019immagine Docker con Geant4, ROOT e Python, come convertirla in un\u2019immagine Apptainer/Singularity e come distribuirla agli altri utenti, senza entrare nei dettagli dei singoli comandi di installazione del software all\u2019interno del container.</p> <p>La costruzione di immagini Docker richiede una macchina con Docker installato e accessibile, ad esempio le macchine come <code>tesla02.recas.infn.ba.it</code>. Un utente pu\u00f2 connettersi a quella macchina con le stesse credenziali delle macchine di frontend <code>ui-al9.recas.infn.ba.it</code>, preparare un <code>Dockerfile</code> e costruire l\u2019immagine. Un esempio completo di <code>Dockerfile</code> per un ambiente Ubuntu 24.04 con Geant4, ROOT e Python3 \u00e8 riportato in appendice, nella sezione Dockerfile di esempio per ambiente Geant4/ROOT.</p> <p>Una volta scritto il <code>Dockerfile</code>, l\u2019utente manutentore pu\u00f2 costruire l\u2019immagine con un comando del tipo:</p> Bash<pre><code>docker build -t registry-clustergpu.recas.ba.infn.it/alice/geant4:10.6.3 .\n</code></pre> <p>In seguito, l\u2019immagine pu\u00f2 essere inviata al registry interno, dove le credenziali sono le stesse del frontend:</p> Bash<pre><code>docker login registry-clustergpu.recas.ba.infn.it\ndocker push registry-clustergpu.recas.ba.infn.it/alice/geant4:10.6.3\n</code></pre> <p>La conversione da immagine Docker a immagine Apptainer/Singularity avviene su un nodo dove Apptainer \u00e8 installato e autorizzato a eseguire il comando <code>build</code>. Un esempio di comando \u00e8:</p> Bash<pre><code>apptainer build G4_v10.6.3.sif \\\n  docker://registry-clustergpu.recas.ba.infn.it/alice/geant4:10.6.3\n</code></pre> <p>Il file <code>G4_v10.6.3.sif</code> cos\u00ec generato pu\u00f2 essere copiato o spostato nella directory condivisa delle immagini:</p> Bash<pre><code>mv G4_v10.6.3.sif /lustrehome/alice/apptainer_images/\n</code></pre> <p>Dopo questo passaggio, tutti gli utenti (come <code>bob</code>) possono usare l\u2019immagine nei propri job Condor creando un symlink nella <code>initialdir</code> e impostando <code>container_image</code> al nome del symlink, come mostrato nella sezione Concetti di base: container, Apptainer e HTCondor e negli esempi.</p>"},{"location":"#comandi-essenziali-docker","title":"Comandi essenziali Docker","text":"<p>Non \u00e8 necessario che ogni utente conosca Docker in dettaglio, ma \u00e8 utile riassumere i comandi pi\u00f9 usati nel ciclo di vita di un\u2019immagine. La costruzione da <code>Dockerfile</code> nella directory corrente avviene di solito con:</p> Bash<pre><code>docker build -t nome_immagine:tag .\n</code></pre> <p>Per visualizzare le immagini locali si pu\u00f2 usare:</p> Bash<pre><code>docker images\n</code></pre> <p>Per testare interattivamente un\u2019immagine, ad esempio verificando che gli script di ambiente siano corretti, si pu\u00f2 avviare un container con:</p> Bash<pre><code>docker run -it nome_immagine:tag\n</code></pre> <p>Infine, per taggare e inviare un\u2019immagine verso il registry remoto, si possono usare comandi del tipo:</p> Bash<pre><code>docker tag nome_immagine:tag \\\n  registry-clustergpu.recas.ba.infn.it/alice/nome_immagine:tag\n\ndocker push registry-clustergpu.recas.ba.infn.it/alice/nome_immagine:tag\n</code></pre> <p>Questi comandi vengono eseguiti sulla macchina che ha Docker installato, come <code>tesla02.recas.infn.ba.it</code>.</p>"},{"location":"#comandi-essenziali-apptainersingularity","title":"Comandi essenziali Apptainer/Singularity","text":"<p>Apptainer viene utilizzato sia per testare manualmente le immagini sia in maniera indiretta tramite HTCondor. Per un test rapido si pu\u00f2 eseguire un comando dentro un\u2019immagine <code>.sif</code> con:</p> Bash<pre><code>apptainer exec G4_v11.3.1.sif geant4-config --version\n</code></pre> <p>Per aprire una shell interattiva nel container si pu\u00f2 usare:</p> Bash<pre><code>apptainer shell G4_v11.3.1.sif\n</code></pre> <p>La conversione da immagine Docker a <code>.sif</code> avviene, come gi\u00e0 mostrato, con:</p> Bash<pre><code>apptainer build G4_v11.3.1.sif \\\n  docker://registry-clustergpu.recas.ba.infn.it/alice/geant4:11.3.1\n</code></pre> <p>I job Condor che usano <code>container_image</code> nascondono questi dettagli, perch\u00e9 \u00e8 il sistema a chiamare internamente Apptainer. Tuttavia, conoscere questi comandi aiuta a testare rapidamente un\u2019immagine su una macchina di frontend prima di costruire i file <code>.csi</code>, come quelli della sezione Esempi.</p>"},{"location":"#sec-kubernetes","title":"Prospettive: uso di Kubernetes con container","text":"<p>(TODO)</p>"},{"location":"#appendice","title":"Appendice","text":""},{"location":"#sec-dockerfile-esempio","title":"Dockerfile di esempio per ambiente Geant4/ROOT","text":"<p>In questa sezione \u00e8 riportato un esempio completo di <code>Dockerfile</code> per costruire un\u2019immagine Docker basata su Ubuntu 24.04, con Geant4, ROOT e Python3. Questo file \u00e8 pensato come base da adattare alle esigenze del gruppo, sia per quanto riguarda le versioni dei software, sia per i path di installazione. Il risultato atteso \u00e8 un\u2019immagine che espone gli script di environment <code>/opt/geant4/bin/geant4.sh</code> e <code>/opt/root/bin/thisroot.sh</code> e che pu\u00f2 essere convertita in un file <code>.sif</code> come descritto nella sezione Costruzione di un\u2019immagine Docker e conversione in SIF.</p> Docker<pre><code>FROM ubuntu:24.04\n\nLABEL author=\"marcocecca\"\nLABEL version=\"G4v11.3.1_Rootv6.36.4_Ubuntu24\"\n\n# ===========================\n# Env Geant4 + ROOT (base)\n# ===========================\nENV DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC\n\nENV G4VERSION=11.3.1\nENV G4INSTALL=/opt/geant4\nENV G4DATA_DIR=$G4INSTALL/share/Geant4/data\nENV G4LIB_DIR=$G4INSTALL/lib\nENV G4GDMLROOT=$G4INSTALL\n\n# ROOT\nENV ROOT_VERSION=6.36.04\nENV ROOTSYS=/opt/root\n\n# ==========================================\n# Dipendenze base (Qt5 + OpenGL/X11 + ROOT + Python + Vdt)\n# ==========================================\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    pkg-config \\\n    ca-certificates \\\n    wget \\\n    curl \\\n    # Geant4 + GDML\n    libxerces-c-dev \\\n    libexpat1-dev \\\n    # Qt5 + OpenGL + X11\n    qtbase5-dev \\\n    qtbase5-dev-tools \\\n    qt5-qmake \\\n    libqt5opengl5-dev \\\n    libx11-dev \\\n    libxmu-dev \\\n    libxi-dev \\\n    libxrandr-dev \\\n    libxinerama-dev \\\n    libxcursor-dev \\\n    libgl1-mesa-dev \\\n    libglu1-mesa-dev \\\n    # runtime Qt/X11\n    libxkbcommon-x11-0 \\\n    libfontconfig1 \\\n    libxrender1 \\\n    libxcb-icccm4 \\\n    libxcb-image0 \\\n    libxcb-keysyms1 \\\n    libxcb-render-util0 \\\n    libxcb-xfixes0 \\\n    libxcb-xinerama0 \\\n    # dipendenze ROOT\n    libxpm-dev \\\n    libxft-dev \\\n    libssl-dev \\\n    libpcre3-dev \\\n    libgsl-dev \\\n    libgraphviz-dev \\\n    libtbb12 \\\n    libtbb-dev \\\n    libvdt-dev \\\n    # Python per gli script di simulazione\n    python3 \\\n    python3-numpy \\\n    python3-matplotlib \\\n    python3-pip \\\n    # utility\n    adduser \\\n &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# ================================\n# Mandatory ReCaS: utente reale\n# ================================\nENV USERNAME=alice\nENV USERID=000001\nENV GROUPID=1234\n\nRUN groupadd -g \"$GROUPID\" \"$USERNAME\" &amp;&amp; \\\n    adduser --disabled-password --gecos '' --uid \"$USERID\" --gid \"$GROUPID\" \"$USERNAME\"\n\n# ==========================================\n# Sorgenti Geant4 11.3.1 (da GitLab CERN)\n# ==========================================\nRUN mkdir -p /opt/geant4-source /tmp/g4 &amp;&amp; \\\n    cd /tmp/g4 &amp;&amp; \\\n    wget https://gitlab.cern.ch/geant4/geant4/-/archive/v11.3.1/geant4-v11.3.1.tar.gz &amp;&amp; \\\n    tar -xzf geant4-v11.3.1.tar.gz -C /opt/geant4-source --strip-components=1 &amp;&amp; \\\n    rm -rf /tmp/g4\n\n# ==========================================\n# Build + install Geant4 (dataset inclusi)\n# ==========================================\nRUN mkdir -p /opt/geant4-build &amp;&amp; cd /opt/geant4-build &amp;&amp; \\\n    cmake ../geant4-source \\\n      -DCMAKE_INSTALL_PREFIX=${G4INSTALL} \\\n      -DGEANT4_BUILD_MULTITHREADED=ON \\\n      -DGEANT4_BUILD_CXXSTD=17 \\\n      -DGEANT4_INSTALL_DATA=ON \\\n      -DGEANT4_INSTALL_EXAMPLES=ON \\\n      -DGEANT4_USE_GDML=ON \\\n      -DGEANT4_USE_SYSTEM_EXPAT=ON \\\n      -DGEANT4_USE_SYSTEM_XERCESC=ON \\\n      -DGEANT4_USE_QT=ON \\\n      -DCMAKE_PREFIX_PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5 \\\n      -DGEANT4_USE_OPENGL_X11=ON \\\n      -DGEANT4_USE_XM=OFF \\\n      -DGEANT4_USE_RAYTRACER_X11=ON &amp;&amp; \\\n    cmake --build . -j\"$(nproc)\" &amp;&amp; \\\n    cmake --install . &amp;&amp; \\\n    rm -rf /opt/geant4-build\n\n# =================================================\n# Install ROOT (precompiled per Ubuntu 24.04)\n# =================================================\nRUN cd /opt &amp;&amp; \\\n    wget -O root.tar.gz https://root.cern/download/root_v6.36.04.Linux-ubuntu24.04-x86_64-gcc13.3.tar.gz &amp;&amp; \\\n    tar -xzf root.tar.gz &amp;&amp; \\\n    mv root root-${ROOT_VERSION} &amp;&amp; \\\n    ln -s root-${ROOT_VERSION} root &amp;&amp; \\\n    rm root.tar.gz\n\n# =================================================\n# Linker config + PATH/LD_LIBRARY_PATH globali\n# =================================================\nRUN echo \"${G4LIB_DIR}\"   &gt; /etc/ld.so.conf.d/geant4.conf &amp;&amp; \\\n    echo \"${ROOTSYS}/lib\" &gt; /etc/ld.so.conf.d/root.conf &amp;&amp; \\\n    ldconfig\n\nENV PATH=${G4INSTALL}/bin:${ROOTSYS}/bin:${PATH}\nENV LD_LIBRARY_PATH=${G4LIB_DIR}:${ROOTSYS}/lib\n\n# ===========================\n# Permessi su /opt/geant4\n# ===========================\nRUN chown -R \"$USERNAME:$GROUPID\" \"$G4INSTALL\"\n\n# ======================================================\n# EntryPoint: inizializza Geant4 + ROOT nel modo \"giusto\"\n# ======================================================\nRUN printf '%s\\n' \\\n'#!/bin/bash' \\\n'set -e' \\\n'# --- Geant4 env ---' \\\n'G4_SH=\"${G4INSTALL}/bin/geant4.sh\"' \\\n'if [ -f \"$G4_SH\" ]; then' \\\n'  OLD_G4=\"$(pwd)\"' \\\n'  cd \"$(dirname \"$G4_SH\")\"' \\\n'  . ./geant4.sh' \\\n'  cd \"$OLD_G4\"' \\\n'fi' \\\n'# --- geant4make (opzionale, per vecchi workflow) ---' \\\n'if [ -f \"${G4INSTALL}/share/Geant4-${G4VERSION}/geant4make/geant4make.sh\" ]; then' \\\n'  . \"${G4INSTALL}/share/Geant4-${G4VERSION}/geant4make/geant4make.sh\"' \\\n'fi' \\\n'# --- ROOT env ---' \\\n'if [ -f \"/opt/root/bin/thisroot.sh\" ]; then' \\\n'  OLD_ROOT=\"$(pwd)\"' \\\n'  cd /opt/root' \\\n'  . bin/thisroot.sh' \\\n'  cd \"$OLD_ROOT\"' \\\n'fi' \\\n'# --- Esegui il comando richiesto ---' \\\n'exec \"$@\"' \\\n&gt; /usr/local/bin/geant4-entrypoint.sh &amp;&amp; \\\nchmod +x /usr/local/bin/geant4-entrypoint.sh\n\nWORKDIR /home/$USERNAME\nUSER $USERNAME\n\nENTRYPOINT [\"/usr/local/bin/geant4-entrypoint.sh\"]\nCMD [\"bash\"]\n</code></pre>"}]}